{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import os\n",
    "import threading\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "class TrainLog:\n",
    "    \"\"\"Saves training logs in Pandas msgpacks\"\"\"\n",
    "\n",
    "    INCREMENTAL_UPDATE_TIME = 300\n",
    "\n",
    "    def __init__(self, directory, name):\n",
    "        self.log_file_path = \"{}/{}.msgpack\".format(directory, name)\n",
    "        self._log = defaultdict(dict)\n",
    "        self._log_lock = threading.RLock()\n",
    "        self._last_update_time = time.time() - self.INCREMENTAL_UPDATE_TIME\n",
    "\n",
    "    def record_single(self, step, column, value):\n",
    "        self._record(step, {column: value})\n",
    "\n",
    "    def record(self, step, col_val_dict):\n",
    "        self._record(step, col_val_dict)\n",
    "\n",
    "    def save(self):\n",
    "        df = self._as_dataframe()\n",
    "        df.to_msgpack(self.log_file_path, compress='zlib')\n",
    "\n",
    "    def _record(self, step, col_val_dict):\n",
    "        with self._log_lock:\n",
    "            self._log[step].update(col_val_dict)\n",
    "            if time.time() - self._last_update_time >= self.INCREMENTAL_UPDATE_TIME:\n",
    "                self._last_update_time = time.time()\n",
    "                self.save()\n",
    "\n",
    "    def _as_dataframe(self):\n",
    "        with self._log_lock:\n",
    "            return DataFrame.from_dict(self._log, orient='index')\n",
    "\n",
    "class RunContext:\n",
    "    \"\"\"Creates directories and files for the run\"\"\"\n",
    "\n",
    "    def __init__(self, runner_file, run_idx):\n",
    "        logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "        runner_name = os.path.basename(runner_file).split(\".\")[0]\n",
    "        self.result_dir = \"{root}/{runner_name}/{date:%Y-%m-%d_%H:%M:%S}/{run_idx}\".format(\n",
    "            root='results',\n",
    "            runner_name=runner_name,\n",
    "            date=datetime.now(),\n",
    "            run_idx=run_idx\n",
    "        )\n",
    "        self.transient_dir = self.result_dir + \"/transient\"\n",
    "        os.makedirs(self.result_dir)\n",
    "        os.makedirs(self.transient_dir)\n",
    "\n",
    "    def create_train_log(self, name):\n",
    "        return TrainLog(self.result_dir, name)\n",
    "\n",
    "\n",
    "# global variable & object\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "LOG = logging.getLogger('main')\n",
    "context = RunContext(os.getcwd(), 0)\n",
    "checkpoint_path = context.transient_dir\n",
    "training_log = context.create_train_log(\"training\")\n",
    "validation_log = context.create_train_log(\"validation\")\n",
    "ema_validation_log = context.create_train_log(\"ema_validation\")\n",
    "\n",
    "\n",
    "args = None\n",
    "best_prec1 = 0\n",
    "global_step = 0\n",
    "NO_LABEL = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494fc60",
   "metadata": {},
   "source": [
    "### Divide images to 11 groups, generate  11 txt files, 'filename label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74804f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from math import ceil\n",
    "\n",
    "# list file name\n",
    "video_dir_path = '/media/yszhao/Data/PublicDataset/Kvasir-Capsule/labeled_videos'  # need to modify\n",
    "nor_image_dir_path = '/media/yszhao/Data/PublicDataset/Kvasir-Capsule/labeled_images/Normal'\n",
    "abnor_image_dir_path = '/media/yszhao/Data/PublicDataset/Kvasir-Capsule/labeled_images/Abnormal'\n",
    "\n",
    "videos = os.listdir(video_dir_path)\n",
    "videos = [video.split('.')[0] for video in videos]\n",
    "num_videos = len(videos)\n",
    "\n",
    "\n",
    "# divide groups\n",
    "n =4\n",
    "videos = [videos[i:i+n] for i in range(0, len(videos), n)]\n",
    "videos\n",
    "\n",
    "# save groups files\n",
    "num_groups = ceil(num_videos/n)  #  =11\n",
    "\n",
    "image_groups = [[] for i in range(num_groups)]   # results of groups divided\n",
    "\n",
    "# write normal\n",
    "for image in os.listdir(nor_image_dir_path):\n",
    "    for i in range(len(image_groups)):\n",
    "        if image.split('_')[0] in videos[i]:\n",
    "            image_groups[i].append(image+' '+'normal')\n",
    "\n",
    "# write abnormal\n",
    "for image in os.listdir(abnor_image_dir_path):\n",
    "    for i in range(len(image_groups)):\n",
    "        if image.split('_')[0] in videos[i]:\n",
    "            image_groups[i].append(image+' '+'abnormal')\n",
    "\n",
    "\n",
    "# write file groups\n",
    "\n",
    "for i in range(len(image_groups)):\n",
    "    textfile = open('{}.txt'.format(i),'w')\n",
    "    for element in image_groups[i]:\n",
    "        textfile.write(element + \"\\n\")\n",
    "        \n",
    "    textfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4ceb41",
   "metadata": {},
   "source": [
    "### Link kv_capsule dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f1296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os \n",
    "\n",
    "nor_image_dir_path = '/media/yszhao/Data/PublicDataset/Kvasir-Capsule/labeled_images/Normal'\n",
    "abnor_image_dir_path = '/media/yszhao/Data/PublicDataset/Kvasir-Capsule/labeled_images/Abnormal'\n",
    "unlabeled_image_dir_path = '/media/yszhao/Data/PublicDataset/Kvasir-Capsule/unlabeled_images'\n",
    "\n",
    "textfile = open('Link kv_capsule dataset.txt','w')\n",
    "text = []\n",
    "\n",
    "for image in os.listdir(nor_image_dir_path):\n",
    "    text.append('ln -s '+ nor_image_dir_path+'/'+image+ ' '+\n",
    "                './data-local/images/kv_capsule/train/normal/'+image)\n",
    "    \n",
    "# print(len(os.listdir(nor_image_dir_path))) \n",
    "\n",
    "for image in os.listdir(abnor_image_dir_path):\n",
    "    text.append('ln -s '+ abnor_image_dir_path+'/'+image+ ' '+\n",
    "                './data-local/images/kv_capsule/train/abnormal/'+image)\n",
    "    \n",
    "# print(len(os.listdir(abnor_image_dir_path)))   \n",
    "\n",
    "unlabel_files = os.listdir(unlabeled_image_dir_path)\n",
    "random.shuffle(unlabel_files)\n",
    "\n",
    "for i in range(100000):\n",
    "    image = unlabel_files[i]\n",
    "    text.append('ln -s '+ unlabeled_image_dir_path+'/'+image+ ' '+\n",
    "                './data-local/images/kv_capsule/train/unlabeled/'+image)\n",
    "\n",
    "# print(len(os.listdir(unlabeled_image_dir_path)))\n",
    "    \n",
    "for element in text:\n",
    "        textfile.write(element + \"\\n\")\n",
    "        \n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746f41e",
   "metadata": {},
   "source": [
    "### Calculate mean and std of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84080bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "traindir = './data-local/images/cifar/cifar10/by-image/train'\n",
    "dataset = torchvision.datasets.ImageFolder(traindir, transforms.ToTensor())\n",
    "dataset.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe25c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def iterate_eternally(indices):\n",
    "    def infinite_shuffles():\n",
    "        while True:\n",
    "            yield np.random.permutation(indices)\n",
    "    return itertools.chain.from_iterable(infinite_shuffles())\n",
    "\n",
    "\n",
    "secondary_iter = iterate_eternally(range(10))\n",
    "secondary_iter\n",
    "itertools.chain.from_iterable('infinite_shuffles()')\n",
    "for i in itertools.chain.from_iterable(range(10)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "m = nn.BatchNorm2d(100, affine=False)\n",
    "input = torch.randn(20, 100, 35, 45)\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66070a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    \n",
    "    for data, _ in loader:\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    mean = channels_sum/num_batches\n",
    "    std = (channels_squared_sum/num_batches - mean**2)**0.5\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=64, shuffle=True)\n",
    "get_mean_std(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4034965",
   "metadata": {},
   "source": [
    "### Extract Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "label_file = './data-local/labels/kv_capsule/10.txt'\n",
    "original_path = './data-local/images/kv_capsule/train'\n",
    "target_path = './data-local/images/kv_capsule/validate'\n",
    "with open(label_file) as f:\n",
    "    for file in f:\n",
    "        if file.split(' ')[1]=='0\\n':\n",
    "            os.rename(original_path+'/normal/'+file.split(' ')[0], target_path+'/normal/'+file.split(' ')[0])\n",
    "        elif file.split(' ')[1]=='1\\n':\n",
    "            os.rename(original_path+'/abnormal/'+file.split(' ')[0], target_path+'/abnormal/'+file.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916d226",
   "metadata": {},
   "source": [
    "### Config: args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c96276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "# from . import architectures, datasets\n",
    "\n",
    "\n",
    "# __all__ = ['parse_cmd_args', 'parse_dict_args']\n",
    "\n",
    "def create_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Cifar-10 Training')\n",
    "    \n",
    "    parser.add_argument('--arch', '-a', metavar='ARCH', default='cifar_shakeshake26',\n",
    "#                         choices=architectures.__all__,\n",
    "                        help='model architecture: ')\n",
    "    \n",
    "    parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 256)')\n",
    "    \n",
    "    parser.add_argument('--checkpoint-epochs', default=1, type=int,\n",
    "                        metavar='EPOCHS', help='checkpoint frequency in epochs, 0 to turn checkpointing off (default: 1)')\n",
    "    \n",
    "    parser.add_argument('--consistency', default=100, type=float, metavar='WEIGHT',\n",
    "                        help='use consistency loss with given weight (default: None)')\n",
    "    \n",
    "    parser.add_argument('--consistency-type', default=\"mse\", type=str, metavar='TYPE',\n",
    "                        choices=['mse', 'kl'],\n",
    "                        help='consistency loss type to use')\n",
    "    \n",
    "    parser.add_argument('--consistency-rampup', default=5, type=int, metavar='EPOCHS',\n",
    "                        help='length of the consistency loss ramp-up')\n",
    "    \n",
    "    parser.add_argument('--dataset', metavar='DATASET', default='cifar10',\n",
    "#                         choices=datasets.__all__,\n",
    "                        help='dataset: ')\n",
    "    \n",
    "    parser.add_argument('--ema-decay', default=0.999, type=float, metavar='ALPHA',     # momentuem of ema\n",
    "                        help='ema variable decay rate (default: 0.999)')\n",
    "    \n",
    "    parser.add_argument('--epochs', default=180, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    \n",
    "    parser.add_argument('-e', '--evaluate', type=str2bool,\n",
    "                        help='evaluate model on evaluation set')\n",
    "    \n",
    "    parser.add_argument('--eval-subdir', type=str, default='val',\n",
    "                        help='the subdirectory inside the data directory that contains the evaluation data')\n",
    "    \n",
    "    parser.add_argument('--evaluation-epochs', default=1, type=int,\n",
    "                        metavar='EPOCHS', help='evaluation frequency in epochs, 0 to turn evaluation off (default: 1)')\n",
    "    \n",
    "    parser.add_argument('--exclude-unlabeled', default=False, type=str2bool, metavar='BOOL',\n",
    "                        help='exclude unlabeled examples from the training set')\n",
    "    \n",
    "    parser.add_argument('--initial-lr', default=0.0, type=float,\n",
    "                        metavar='LR', help='initial learning rate when using linear rampup')\n",
    "    \n",
    "    parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    \n",
    "    parser.add_argument('--labels', default='data-local/labels/cifar10/1000_balanced_labels/00.txt', \n",
    "                        type=str, metavar='FILE',\n",
    "                        help='list of image labels (default: based on directory structure)')\n",
    "    \n",
    "    parser.add_argument('--labeled-batch-size', default=62, type=int,\n",
    "                        metavar='N', help=\"labeled examples per minibatch (default: no constrain)\")\n",
    "    \n",
    "    parser.add_argument('--logit-distance-cost', default=-1, type=float, metavar='WEIGHT',\n",
    "                        help='let the student model have two outputs and use an MSE loss between the logits with the given weight (default: only have one output)')\n",
    "    \n",
    "    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                        metavar='LR', help='max learning rate')\n",
    "\n",
    "    parser.add_argument('--lr-rampup', default=0, type=int, metavar='EPOCHS',\n",
    "                        help='length of leabrning rate rampup in the beginning')\n",
    "    \n",
    "    parser.add_argument('--lr-rampdown-epochs', default=None, type=int, metavar='EPOCHS',\n",
    "                        help='length of learning rate cosine rampdown (>= length of training)')\n",
    "    \n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                        help='momentum')\n",
    "    \n",
    "    parser.add_argument('--num_classes', default=10, type=int, metavar='N',\n",
    "                        help='number of classes (default: 10)')\n",
    "    \n",
    "    parser.add_argument('--nesterov', default=False, type=str2bool,\n",
    "                        help='use nesterov momentum', metavar='BOOL')\n",
    "    \n",
    "    parser.add_argument('--pretrained', default=False, dest='pretrained', action='store_true',\n",
    "                        help='use pre-trained model')\n",
    "    \n",
    "    parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                        metavar='N', help='print frequency (default: 10)')\n",
    "    \n",
    "    parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                        help='path to latest checkpoint (default: none)')\n",
    "     \n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='manual epoch number (useful on restarts)')\n",
    "    \n",
    "    parser.add_argument('--train-subdir', type=str, default='train',\n",
    "                        help='the subdirectory inside the data directory that contains the training data')\n",
    "    \n",
    "    parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)')\n",
    "    \n",
    "    return parser\n",
    "\n",
    "\n",
    "def parse_commandline_args():\n",
    "    return create_parser().parse_args([])\n",
    "\n",
    "def parse_dict_args(**kwargs):\n",
    "    def to_cmdline_kwarg(key, value):\n",
    "        if len(key) == 1:\n",
    "            key = \"-{}\".format(key)\n",
    "        else:\n",
    "            key = \"--{}\".format(re.sub(r\"_\", \"-\", key))\n",
    "        value = str(value)\n",
    "        return key, value\n",
    "\n",
    "    kwargs_pairs = (to_cmdline_kwarg(key, value)\n",
    "                    for key, value in kwargs.items())\n",
    "    cmdline_args = list(sum(kwargs_pairs, ()))\n",
    "\n",
    "    LOG.info(\"Using these command line args: %s\", \" \".join(cmdline_args))\n",
    "\n",
    "    return create_parser().parse_args(cmdline_args)\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "\n",
    "def str2epochs(v):\n",
    "    try:\n",
    "        if len(v) == 0:\n",
    "            epochs = []\n",
    "        else:\n",
    "            epochs = [int(string) for string in v.split(\",\")]\n",
    "    except:\n",
    "        raise argparse.ArgumentTypeError(\n",
    "            'Expected comma-separated list of integers, got \"{}\"'.format(v))\n",
    "    if not all(0 < epoch1 < epoch2 for epoch1, epoch2 in zip(epochs[:-1], epochs[1:])):\n",
    "        raise argparse.ArgumentTypeError(\n",
    "            'Expected the epochs to be listed in increasing order')\n",
    "    return epochs\n",
    "\n",
    "\n",
    "args = parse_commandline_args()\n",
    "args.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cff16",
   "metadata": {},
   "source": [
    "### Create/Load model. (why it has 2  fc layers??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c5eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "def export(fn):\n",
    "    mod = sys.modules[fn.__module__]\n",
    "    if hasattr(mod, '__all__'):\n",
    "        mod.__all__.append(fn.__name__)\n",
    "    else:\n",
    "        mod.__all__ = [fn.__name__]\n",
    "    return fn\n",
    "\n",
    "def parameter_count(module):\n",
    "    return sum(int(param.numel()) for param in module.parameters())\n",
    "\n",
    "'''Load cifar_shakeshake26'''\n",
    "@export\n",
    "def cifar_shakeshake26(pretrained=False, **kwargs):      # This architecture is similar with ResNet, which is designed for cifar dataset.\n",
    "    assert not pretrained\n",
    "    model = ResNet32x32(ShakeShakeBlock,         #  ShakeShakeBlock also means BasicBlock in ResNet\n",
    "                        layers=[4, 4, 4],\n",
    "                        channels=96,\n",
    "                        downsample='shift_conv', **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "class ResNet32x32(nn.Module):\n",
    "    def __init__(self, block, layers, channels, groups=1, num_classes=1000, downsample='basic'):\n",
    "        super().__init__()\n",
    "        assert len(layers) == 3\n",
    "        self.downsample_mode = downsample\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, channels, groups, layers[0])\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, channels * 2, groups, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, channels * 4, groups, layers[2], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.fc1 = nn.Linear(block.out_channels(\n",
    "            channels * 4, groups), num_classes)\n",
    "        self.fc2 = nn.Linear(block.out_channels(\n",
    "            channels * 4, groups), num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, groups, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != block.out_channels(planes, groups):\n",
    "            if self.downsample_mode == 'basic' or stride == 1:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv2d(self.inplanes, block.out_channels(planes, groups),\n",
    "                              kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.BatchNorm2d(block.out_channels(planes, groups)),\n",
    "                )\n",
    "            elif self.downsample_mode == 'shift_conv':\n",
    "                downsample = ShiftConvDownsample(in_channels=self.inplanes,\n",
    "                                                 out_channels=block.out_channels(planes, groups))\n",
    "            else:\n",
    "                assert False\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, stride, downsample))\n",
    "        self.inplanes = block.out_channels(planes, groups)\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc1(x), self.fc2(x)\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class ShakeShakeBlock(nn.Module):\n",
    "    @classmethod\n",
    "    def out_channels(cls, planes, groups):\n",
    "        assert groups == 1\n",
    "        return planes\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        assert groups == 1\n",
    "        self.conv_a1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn_a1 = nn.BatchNorm2d(planes)\n",
    "        self.conv_a2 = conv3x3(planes, planes)\n",
    "        self.bn_a2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv_b1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn_b1 = nn.BatchNorm2d(planes)\n",
    "        self.conv_b2 = conv3x3(planes, planes)\n",
    "        self.bn_b2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        a, b, residual = x, x, x\n",
    "\n",
    "        a = F.relu(a, inplace=False)\n",
    "        a = self.conv_a1(a)\n",
    "        a = self.bn_a1(a)\n",
    "        a = F.relu(a, inplace=True)\n",
    "        a = self.conv_a2(a)\n",
    "        a = self.bn_a2(a)\n",
    "\n",
    "        b = F.relu(b, inplace=False)\n",
    "        b = self.conv_b1(b)\n",
    "        b = self.bn_b1(b)\n",
    "        b = F.relu(b, inplace=True)\n",
    "        b = self.conv_b2(b)\n",
    "        b = self.bn_b2(b)\n",
    "\n",
    "        ab = shake(a, b, training=self.training)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        return residual + ab\n",
    "\n",
    "\n",
    "class Shake(Function):\n",
    "    @classmethod\n",
    "    def forward(cls, ctx, inp1, inp2, training):\n",
    "        assert inp1.size() == inp2.size()\n",
    "        gate_size = [inp1.size()[0], *itertools.repeat(1, inp1.dim() - 1)]\n",
    "        gate = inp1.new(*gate_size)\n",
    "        if training:\n",
    "            gate.uniform_(0, 1)\n",
    "        else:\n",
    "            gate.fill_(0.5)\n",
    "        return inp1 * gate + inp2 * (1. - gate)\n",
    "\n",
    "    @classmethod\n",
    "    def backward(cls, ctx, grad_output):\n",
    "        grad_inp1 = grad_inp2 = grad_training = None\n",
    "        gate_size = [grad_output.size()[0], *itertools.repeat(1,\n",
    "                                                              grad_output.dim() - 1)]\n",
    "        gate = grad_output.data.new(*gate_size).uniform_(0, 1).clone()\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_inp1 = grad_output * gate\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_inp2 = grad_output * (1 - gate)\n",
    "        assert not ctx.needs_input_grad[2]\n",
    "        return grad_inp1, grad_inp2, grad_training\n",
    "\n",
    "\n",
    "def shake(inp1, inp2, training=False):\n",
    "    return Shake.apply(inp1, inp2, training)\n",
    "\n",
    "\n",
    "class ShiftConvDownsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(in_channels=2 * in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=1,\n",
    "                              groups=2)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat((x[:, :, 0::2, 0::2],\n",
    "                       x[:, :, 1::2, 1::2]), dim=1)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# '''maybe this is for imagenet,leave it'''\n",
    "\n",
    "# @export\n",
    "# class BottleneckBlock(nn.Module):\n",
    "#     @classmethod\n",
    "#     def out_channels(cls, planes, groups):\n",
    "#         if groups > 1:\n",
    "#             return 2 * planes\n",
    "#         else:\n",
    "#             return 4 * planes\n",
    "\n",
    "#     def __init__(self, inplanes, planes, groups, stride=1, downsample=None):\n",
    "#         super().__init__()\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "#         self.conv_a1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "#         self.bn_a1 = nn.BatchNorm2d(planes)\n",
    "#         self.conv_a2 = nn.Conv2d(\n",
    "#             planes, planes, kernel_size=3, stride=stride, padding=1, bias=False, groups=groups)\n",
    "#         self.bn_a2 = nn.BatchNorm2d(planes)\n",
    "#         self.conv_a3 = nn.Conv2d(planes, self.out_channels(\n",
    "#             planes, groups), kernel_size=1, bias=False)\n",
    "#         self.bn_a3 = nn.BatchNorm2d(self.out_channels(planes, groups))\n",
    "\n",
    "#         self.downsample = downsample\n",
    "#         self.stride = stride\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         a, residual = x, x\n",
    "\n",
    "#         a = self.conv_a1(a)\n",
    "#         a = self.bn_a1(a)\n",
    "#         a = self.relu(a)\n",
    "#         a = self.conv_a2(a)\n",
    "#         a = self.bn_a2(a)\n",
    "#         a = self.relu(a)\n",
    "#         a = self.conv_a3(a)\n",
    "#         a = self.bn_a3(a)\n",
    "\n",
    "#         if self.downsample is not None:\n",
    "#             residual = self.downsample(residual)\n",
    "\n",
    "#         return self.relu(residual + a)\n",
    "    \n",
    "# def resnext152(pretrained=False, **kwargs):\n",
    "#     assert not pretrained\n",
    "#     model = ResNet224x224(BottleneckBlock,\n",
    "#                           layers=[3, 8, 36, 3],\n",
    "#                           channels=32 * 4,\n",
    "#                           groups=32,\n",
    "#                           downsample='basic', **kwargs)\n",
    "#     return model\n",
    "\n",
    "# class ResNet224x224(nn.Module):\n",
    "#     def __init__(self, block, layers, channels, groups=1, num_classes=1000, downsample='basic'):\n",
    "#         super().__init__()\n",
    "#         assert len(layers) == 4\n",
    "#         self.downsample_mode = downsample\n",
    "#         self.inplanes = 64\n",
    "#         self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "#                                bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "#         self.layer1 = self._make_layer(block, channels, groups, layers[0])\n",
    "#         self.layer2 = self._make_layer(\n",
    "#             block, channels * 2, groups, layers[1], stride=2)\n",
    "#         self.layer3 = self._make_layer(\n",
    "#             block, channels * 4, groups, layers[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(\n",
    "#             block, channels * 8, groups, layers[3], stride=2)\n",
    "#         self.avgpool = nn.AvgPool2d(7)\n",
    "#         self.fc1 = nn.Linear(block.out_channels(\n",
    "#             channels * 8, groups), num_classes)\n",
    "#         self.fc2 = nn.Linear(block.out_channels(\n",
    "#             channels * 8, groups), num_classes)\n",
    "\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "#                 m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "\n",
    "#     def _make_layer(self, block, planes, groups, blocks, stride=1):\n",
    "#         downsample = None\n",
    "#         if stride != 1 or self.inplanes != block.out_channels(planes, groups):\n",
    "#             if self.downsample_mode == 'basic' or stride == 1:\n",
    "#                 downsample = nn.Sequential(\n",
    "#                     nn.Conv2d(self.inplanes, block.out_channels(planes, groups),\n",
    "#                               kernel_size=1, stride=stride, bias=False),\n",
    "#                     nn.BatchNorm2d(block.out_channels(planes, groups)),\n",
    "#                 )\n",
    "#             elif self.downsample_mode == 'shift_conv':\n",
    "#                 downsample = ShiftConvDownsample(in_channels=self.inplanes,\n",
    "#                                                  out_channels=block.out_channels(planes, groups))\n",
    "#             else:\n",
    "#                 assert False\n",
    "\n",
    "#         layers = []\n",
    "#         layers.append(block(self.inplanes, planes, groups, stride, downsample))\n",
    "#         self.inplanes = block.out_channels(planes, groups)\n",
    "#         for i in range(1, blocks):\n",
    "#             layers.append(block(self.inplanes, planes, groups))\n",
    "\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.maxpool(x)\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         return self.fc1(x), self.fc2(x)\n",
    "\n",
    "\n",
    "'''Parse the model parameters.'''\n",
    "def parameters_string(module):\n",
    "    lines = [\n",
    "        \"\",\n",
    "        \"List of model parameters:\",\n",
    "        \"=========================\",\n",
    "    ]\n",
    "\n",
    "    row_format = \"{name:<40} {shape:>20} ={total_size:>12,d}\"\n",
    "    params = list(module.named_parameters())\n",
    "    for name, param in params:\n",
    "        lines.append(row_format.format(\n",
    "            name=name,\n",
    "            shape=\" * \".join(str(p) for p in param.size()),\n",
    "            total_size=param.numel()\n",
    "        ))\n",
    "    lines.append(\"=\" * 75)\n",
    "    lines.append(row_format.format(\n",
    "        name=\"all parameters\",\n",
    "        shape=\"sum of above\",\n",
    "        total_size=sum(int(param.numel()) for name, param in params)\n",
    "    ))\n",
    "    lines.append(\"\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def create_model(ema=False):\n",
    "\n",
    "    LOG.info(\"=> creating {pretrained}{ema}model '{arch}'\".format(\n",
    "            pretrained='pre-trained' if args.pretrained else '',\n",
    "            ema='EMA ' if ema else '',\n",
    "            arch=args.arch))\n",
    "    \n",
    "    model = cifar_shakeshake26(pretrained=args.pretrained, num_classes=args.num_classes).cuda()   \n",
    "    if ema:\n",
    "        for param in model.parameters():\n",
    "            param.detach_()   # detach_() is in-place version of  detach(), the result will never require gradient, \n",
    "                                # just need calculate mean and update by EMA method. --zys\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "ema_model = create_model(ema=True)\n",
    "LOG.info(parameters_string(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa6eb6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): ConvBNActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (1): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "def parameters_string(module):\n",
    "    lines = [\n",
    "        \"\",\n",
    "        \"List of model parameters:\",\n",
    "        \"=========================\",\n",
    "    ]\n",
    "\n",
    "    row_format = \"{name:<40} {shape:>20} ={total_size:>12,d}\"\n",
    "    params = list(module.named_parameters())\n",
    "    for name, param in params:\n",
    "        lines.append(row_format.format(\n",
    "            name=name,\n",
    "            shape=\" * \".join(str(p) for p in param.size()),\n",
    "            total_size=param.numel()\n",
    "        ))\n",
    "    lines.append(\"=\" * 75)\n",
    "    lines.append(row_format.format(\n",
    "        name=\"all parameters\",\n",
    "        shape=\"sum of above\",\n",
    "        total_size=sum(int(param.numel()) for name, param in params)\n",
    "    ))\n",
    "    lines.append(\"\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "model = torchvision.models.mobilenet_v3_small()\n",
    "# model = torchvision.models.resnet18()\n",
    "\n",
    "pretrain = nn.Sequential(*list(model.children())[:-1])\n",
    "pretrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "m = nn.Sequential(\n",
    "    nn.ConvTranspose2d(\n",
    "        in_channels=576, out_channels=1024, kernel_size=4, stride=1, padding=0\n",
    "    ),\n",
    "    nn.ConvTranspose2d(\n",
    "        in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1\n",
    "    ),\n",
    "    nn.ConvTranspose2d(\n",
    "        in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1\n",
    "    ),\n",
    "    nn.ConvTranspose2d(\n",
    "        in_channels=256, out_channels=3, kernel_size=4, stride=2, padding=1\n",
    "    )\n",
    ")\n",
    "\n",
    "x = torch.randn(256, 576, 1, 1)\n",
    "y = m(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e8be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.max(torch.rand((30,30),device='cuda')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ab2fe",
   "metadata": {},
   "source": [
    "### Load Dataset (cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "\n",
    "class RandomTranslateWithReflect:\n",
    "    \"\"\"Translate image randomly\n",
    "\n",
    "    Translate vertically and horizontally by n pixels where\n",
    "    n is integer drawn uniformly independently for each axis\n",
    "    from [-max_translation, max_translation].\n",
    "\n",
    "    Fill the uncovered blank area with reflect padding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_translation):\n",
    "        self.max_translation = max_translation\n",
    "\n",
    "    def __call__(self, old_image):\n",
    "        xtranslation, ytranslation = np.random.randint(-self.max_translation,\n",
    "                                                       self.max_translation + 1,\n",
    "                                                       size=2)\n",
    "        xpad, ypad = abs(xtranslation), abs(ytranslation)\n",
    "        xsize, ysize = old_image.size\n",
    "\n",
    "        flipped_lr = old_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        flipped_tb = old_image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        flipped_both = old_image.transpose(Image.ROTATE_180)\n",
    "\n",
    "        new_image = Image.new(\"RGB\", (xsize + 2 * xpad, ysize + 2 * ypad))\n",
    "\n",
    "        new_image.paste(old_image, (xpad, ypad))\n",
    "\n",
    "        new_image.paste(flipped_lr, (xpad + xsize - 1, ypad))\n",
    "        new_image.paste(flipped_lr, (xpad - xsize + 1, ypad))\n",
    "\n",
    "        new_image.paste(flipped_tb, (xpad, ypad + ysize - 1))\n",
    "        new_image.paste(flipped_tb, (xpad, ypad - ysize + 1))\n",
    "\n",
    "        new_image.paste(flipped_both, (xpad - xsize + 1, ypad - ysize + 1))\n",
    "        new_image.paste(flipped_both, (xpad + xsize - 1, ypad - ysize + 1))\n",
    "        new_image.paste(flipped_both, (xpad - xsize + 1, ypad + ysize - 1))\n",
    "        new_image.paste(flipped_both, (xpad + xsize - 1, ypad + ysize - 1))\n",
    "\n",
    "        new_image = new_image.crop((xpad - xtranslation,\n",
    "                                    ypad - ytranslation,\n",
    "                                    xpad + xsize - xtranslation,\n",
    "                                    ypad + ysize - ytranslation))\n",
    "        return new_image\n",
    "    \n",
    "class TransformTwice:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        out1 = self.transform(inp)\n",
    "        out2 = self.transform(inp)\n",
    "        return out1, out2\n",
    "\n",
    "def export(fn):\n",
    "    mod = sys.modules[fn.__module__]\n",
    "    if hasattr(mod, '__all__'):\n",
    "        mod.__all__.append(fn.__name__)\n",
    "    else:\n",
    "        mod.__all__ = [fn.__name__]\n",
    "    return fn\n",
    "@export\n",
    "def cifar10():\n",
    "    channel_stats = dict(mean=[0.4914, 0.4822, 0.4465],    # how to get these values?  --zys\n",
    "                         std=[0.2470,  0.2435,  0.2616])\n",
    "    train_transformation = TransformTwice(transforms.Compose([\n",
    "        RandomTranslateWithReflect(4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**channel_stats)\n",
    "    ]))\n",
    "    eval_transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**channel_stats)\n",
    "    ])\n",
    "\n",
    "    return {\n",
    "        'train_transformation': train_transformation,  #TransformTwice, return 2 results.  --zys\n",
    "        'eval_transformation': eval_transformation,\n",
    "        'datadir': 'data-local/images/cifar/cifar10/by-image',\n",
    "        'num_classes': 10\n",
    "    }\n",
    "\n",
    "def assert_exactly_one(lst):\n",
    "    assert sum(int(bool(el)) for el in lst) == 1, \", \".join(str(el)\n",
    "                                                            for el in lst)\n",
    "    \n",
    "def relabel_dataset(dataset, labels):     # lables: cifar_1000_balanced_labels in 'data-local-labels-cifar, eg: 45313_airplane.png airplane'\n",
    "    unlabeled_idxs = []\n",
    "    for idx in range(len(dataset.imgs)):\n",
    "        path, _ = dataset.imgs[idx]\n",
    "        filename = os.path.basename(path)\n",
    "        if filename in labels:\n",
    "            label_idx = dataset.class_to_idx[labels[filename]]\n",
    "            dataset.imgs[idx] = path, label_idx\n",
    "            del labels[filename]\n",
    "        else:\n",
    "            dataset.imgs[idx] = path, NO_LABEL\n",
    "            unlabeled_idxs.append(idx)\n",
    "\n",
    "    if len(labels) != 0:\n",
    "        message = \"List of unlabeled contains {} unknown files: {}, ...\"\n",
    "        some_missing = ', '.join(list(labels.keys())[:5])\n",
    "        raise LookupError(message.format(len(labels), some_missing))\n",
    "\n",
    "    labeled_idxs = sorted(set(range(len(dataset.imgs))) - set(unlabeled_idxs))\n",
    "\n",
    "    return labeled_idxs, unlabeled_idxs\n",
    "\n",
    "\n",
    "\n",
    "def iterate_once(iterable):\n",
    "    return np.random.permutation(iterable)\n",
    "\n",
    "def iterate_eternally(indices):\n",
    "    def infinite_shuffles():\n",
    "        while True:\n",
    "            yield np.random.permutation(indices)\n",
    "    return itertools.chain.from_iterable(infinite_shuffles())\n",
    "\n",
    "def grouper(iterable, n):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3) --> ABC DEF\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip(*args)\n",
    "\n",
    "class TwoStreamBatchSampler(Sampler):\n",
    "    \"\"\"Iterate two sets of indices\n",
    "\n",
    "    An 'epoch' is one iteration through the primary indices.\n",
    "    During the epoch, the secondary indices are iterated through\n",
    "    as many times as needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, primary_indices, secondary_indices, batch_size, secondary_batch_size):\n",
    "        self.primary_indices = primary_indices  #  unlabeled_idxs  --zys\n",
    "        self.secondary_indices = secondary_indices #  labeled_idxs  --zys\n",
    "        self.secondary_batch_size = secondary_batch_size   #   unlabeled_idxs_ batch_size  --zys\n",
    "        self.primary_batch_size = batch_size - secondary_batch_size  #   labeled_idxs_ batch_size  --zys\n",
    "\n",
    "        assert len(self.primary_indices) >= self.primary_batch_size > 0\n",
    "        assert len(self.secondary_indices) >= self.secondary_batch_size > 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        primary_iter = iterate_once(self.primary_indices)\n",
    "        secondary_iter = iterate_eternally(self.secondary_indices)\n",
    "        return (\n",
    "            primary_batch + secondary_batch\n",
    "            for (primary_batch, secondary_batch)\n",
    "            in  zip(grouper(primary_iter, self.primary_batch_size),\n",
    "                    grouper(secondary_iter, self.secondary_batch_size))\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.primary_indices) // self.primary_batch_size\n",
    "\n",
    "\n",
    "def create_data_loaders(train_transformation,       # **dataset_config, args=args  --zys\n",
    "                        eval_transformation,\n",
    "                        datadir,\n",
    "                        args):\n",
    "    traindir = os.path.join(datadir, args.train_subdir)\n",
    "    evaldir = os.path.join(datadir, args.eval_subdir)\n",
    "\n",
    "    assert_exactly_one([args.exclude_unlabeled, args.labeled_batch_size]) # args.exclude_unlabeled=False,\n",
    "                                                                        # args.labeled_batch_size = 62  --zys\n",
    "\n",
    "    dataset = torchvision.datasets.ImageFolder(traindir, train_transformation)\n",
    "\n",
    "    if args.labels:   # 'args.labels' is path of cidar10_1000 balanced labels.   --zys\n",
    "        with open(args.labels) as f:\n",
    "            labels = dict(line.split(' ') for line in f.read().splitlines())   # 1000 labeled images  --zys\n",
    "        labeled_idxs, unlabeled_idxs = relabel_dataset(dataset, labels)\n",
    "\n",
    "    if args.exclude_unlabeled:     # exclude unlabeled dataset,default=False  --zys\n",
    "        sampler = SubsetRandomSampler(labeled_idxs)\n",
    "        batch_sampler = BatchSampler(sampler, args.batch_size, drop_last=True)\n",
    "    elif args.labeled_batch_size:     # include labeled and unlabeled dataset  --zys\n",
    "        batch_sampler = TwoStreamBatchSampler(  # batch_size = 256, labeled_batch_size = 62. --zys\n",
    "            unlabeled_idxs, labeled_idxs, args.batch_size, args.labeled_batch_size)    # return set(dataset)-cifar10_1000_balanced_labels  --zys\n",
    "    else:\n",
    "        assert False, \"labeled batch size {}\".format(args.labeled_batch_size)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,        # include labeled and unlabeled dataset  --zys\n",
    "                                               batch_sampler=batch_sampler,\n",
    "                                               num_workers=args.workers,\n",
    "                                               pin_memory=True)\n",
    "\n",
    "    eval_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.ImageFolder(evaldir, eval_transformation),  #  data dir, data transform. --zys\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2 * args.workers,  # Needs images twice as fast\n",
    "        pin_memory=True,\n",
    "        drop_last=False)\n",
    "\n",
    "    return train_loader, eval_loader\n",
    "\n",
    "dataset_config = cifar10()   # dictionary type, args.dataset= cifar10, return train_transformation, \n",
    "                                                    # envl_trans, dataset dir, num_classes...   --zys\n",
    "num_classes = dataset_config.pop('num_classes')\n",
    "\n",
    "train_loader, eval_loader = create_data_loaders(**dataset_config, args=args)  # load cifar10 dataset.\n",
    "train_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22371df6",
   "metadata": {},
   "source": [
    "### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(eval_loader, model, log, global_step, epoch):\n",
    "    class_criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=NO_LABEL).cuda()\n",
    "    meters = AverageMeterSet()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(eval_loader):\n",
    "        meters.update('data_time', time.time() - end)\n",
    "\n",
    "        input_var = input.to('cuda')\n",
    "        # target_var = torch.autograd.Variable(target.cuda(async=True), volatile=True)\n",
    "        target_var = target.to('cuda')    # --zys\n",
    "\n",
    "        minibatch_size = len(target_var)\n",
    "        labeled_minibatch_size = target_var.data.ne(NO_LABEL).sum()\n",
    "        assert labeled_minibatch_size > 0\n",
    "        meters.update('labeled_minibatch_size', labeled_minibatch_size)\n",
    "\n",
    "        # compute output\n",
    "        output1, output2 = model(input_var)\n",
    "        softmax1, softmax2 = F.softmax(output1, dim=1), F.softmax(output2, dim=1)\n",
    "        class_loss = class_criterion(output1, target_var) / minibatch_size\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output1.data, target_var.data, topk=(1, 5))\n",
    "#         meters.update('class_loss', class_loss.data[0], labeled_minibatch_size)\n",
    "        meters.update('class_loss', class_loss.data, labeled_minibatch_size)   #  -zys\n",
    "        meters.update('top1', prec1, labeled_minibatch_size)\n",
    "        meters.update('error1', 100.0 - prec1, labeled_minibatch_size)\n",
    "        meters.update('top5', prec5, labeled_minibatch_size)\n",
    "        meters.update('error5', 100.0 - prec5, labeled_minibatch_size)\n",
    "\n",
    "        # measure elapsed time\n",
    "        meters.update('batch_time', time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "#         if i % args.print_freq == 0:\n",
    "#             LOG.info(\n",
    "#                 'Test: [{0}/{1}]\\t'\n",
    "#                 'Time {meters[batch_time]:.3f}\\t'\n",
    "#                 'Data {meters[data_time]:.3f}\\t'\n",
    "#                 'Class {meters[class_loss]:.4f}\\t'\n",
    "#                 'Prec@1 {meters[top1]:.3f}\\t'\n",
    "#                 'Prec@5 {meters[top5]:.3f}'.format(\n",
    "#                     i, len(eval_loader), meters=meters))\n",
    "\n",
    "    LOG.info(' * Prec@1 {top1.avg:.3f}\\tPrec@5 {top5.avg:.3f}'\n",
    "          .format(top1=meters['top1'], top5=meters['top5']))\n",
    "    log.record(epoch, {\n",
    "        'step': global_step,\n",
    "        **meters.values(),\n",
    "        **meters.averages(),\n",
    "        **meters.sums()\n",
    "    })\n",
    "\n",
    "    return meters['top1'].avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c4a69",
   "metadata": {},
   "source": [
    "### Check resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa817e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if args.resume:\n",
    "    assert os.path.isfile(args.resume), \"=> no checkpoint found at '{}'\".format(args.resume)\n",
    "    LOG.info(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "    # load from args.resume\n",
    "    checkpoint = torch.load(args.resume)\n",
    "    args.start_epoch = checkpoint['epoch']\n",
    "    global_step = checkpoint['global_step']\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    ema_model.load_state_dict(checkpoint['ema_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    LOG.info(\"=> loaded checkpoint '{}' (epoch {})\".format(args.resume, checkpoint['epoch']))\n",
    "    \n",
    "# validate the preloaded model\n",
    "    if args.evaluate:\n",
    "        LOG.info(\"Evaluating the primary model:\")\n",
    "        validate(eval_loader, model, validation_log, global_step, args.start_epoch)\n",
    "        LOG.info(\"Evaluating the EMA model:\")\n",
    "        validate(eval_loader, ema_model, ema_validation_log, global_step, args.start_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5781f56",
   "metadata": {},
   "source": [
    "### Create Optimizer (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a30b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay,\n",
    "                                nesterov=args.nesterov)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c73cb3",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def softmax_mse_loss(input_logits, target_logits):\n",
    "    \"\"\"Takes softmax on both sides and returns MSE loss\n",
    "\n",
    "    Note:\n",
    "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
    "      if you want the mean.\n",
    "    - Sends gradients to inputs but not the targets.\n",
    "    \"\"\"\n",
    "    assert input_logits.size() == target_logits.size()\n",
    "    input_softmax = F.softmax(input_logits, dim=1)\n",
    "    target_softmax = F.softmax(target_logits, dim=1)\n",
    "    num_classes = input_logits.size()[1]\n",
    "    return F.mse_loss(input_softmax, target_softmax, reduction='sum') / num_classes\n",
    "\n",
    "def softmax_kl_loss(input_logits, target_logits):\n",
    "    \"\"\"Takes softmax on both sides and returns KL divergence\n",
    "\n",
    "    Note:\n",
    "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
    "      if you want the mean.\n",
    "    - Sends gradients to inputs but not the targets.\n",
    "    \"\"\"\n",
    "    assert input_logits.size() == target_logits.size()\n",
    "    input_log_softmax = F.log_softmax(input_logits, dim=1)\n",
    "    target_softmax = F.softmax(target_logits, dim=1)\n",
    "    return F.kl_div(input_log_softmax, target_softmax, reduction='sum')\n",
    "\n",
    "def symmetric_mse_loss(input1, input2):\n",
    "    \"\"\"Like F.mse_loss but sends gradients to both directions\n",
    "\n",
    "    Note:\n",
    "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
    "      if you want the mean.\n",
    "    - Sends gradients to both input1 and input2.\n",
    "    \"\"\"\n",
    "    assert input1.size() == input2.size()\n",
    "    num_classes = input1.size()[1]\n",
    "    return torch.sum((input1 - input2)**2) / num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc27e1",
   "metadata": {},
   "source": [
    "### Ramp-up Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid_rampup(current, rampup_length):\n",
    "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(np.exp(-5.0 * phase * phase))\n",
    "\n",
    "\n",
    "def linear_rampup(current, rampup_length):\n",
    "    \"\"\"Linear rampup\"\"\"\n",
    "    assert current >= 0 and rampup_length >= 0\n",
    "    if current >= rampup_length:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return current / rampup_length\n",
    "\n",
    "\n",
    "def cosine_rampdown(current, rampdown_length):\n",
    "    \"\"\"Cosine rampdown from https://arxiv.org/abs/1608.03983\"\"\"\n",
    "    assert 0 <= current <= rampdown_length\n",
    "    return float(.5 * (np.cos(np.pi * current / rampdown_length) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4d3ab",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AverageMeterSet:\n",
    "    def __init__(self):\n",
    "        self.meters = {}\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.meters[key]\n",
    "\n",
    "    def update(self, name, value, n=1):\n",
    "        if not name in self.meters:\n",
    "            self.meters[name] = AverageMeter()\n",
    "        self.meters[name].update(value, n)\n",
    "\n",
    "    def reset(self):\n",
    "        for meter in self.meters.values():\n",
    "            meter.reset()\n",
    "\n",
    "    def values(self, postfix=''):\n",
    "        return {name + postfix: meter.val for name, meter in self.meters.items()}\n",
    "\n",
    "    def averages(self, postfix='/avg'):\n",
    "        return {name + postfix: meter.avg for name, meter in self.meters.items()}\n",
    "\n",
    "    def sums(self, postfix='/sum'):\n",
    "        return {name + postfix: meter.sum for name, meter in self.meters.items()}\n",
    "\n",
    "    def counts(self, postfix='/count'):\n",
    "        return {name + postfix: meter.count for name, meter in self.meters.items()}\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __format__(self, format):\n",
    "        return \"{self.val:{format}} ({self.avg:{format}})\".format(self=self, format=format)\n",
    "\n",
    "    \n",
    "def get_current_consistency_weight(epoch):\n",
    "    # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "    return args.consistency * sigmoid_rampup(epoch, args.consistency_rampup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a6912f",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f83012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    print('output size: {}'.format(output.shape))\n",
    "    maxk = max(topk)\n",
    "    labeled_minibatch_size = max(target.ne(NO_LABEL).sum(), 1e-8)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    \n",
    "    pred = pred.t()    # --transpose, I don't know how t()method can transpose the matrix,  --zys\n",
    "    print('pred_topk: {}'.format(pred.shape))\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    print('correct:{}'.format(correct.shape))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "#         print(correct[:k].shape)\n",
    "        correct_k = correct[:k].float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / labeled_minibatch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf10ab0",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca75156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, step_in_epoch, total_steps_in_epoch):\n",
    "    lr = args.lr\n",
    "    epoch = epoch + step_in_epoch / total_steps_in_epoch\n",
    "\n",
    "    # LR warm-up to handle large minibatch sizes from https://arxiv.org/abs/1706.02677\n",
    "    lr = linear_rampup(epoch, args.lr_rampup) * (args.lr - args.initial_lr) + args.initial_lr\n",
    "\n",
    "    # Cosine LR rampdown from https://arxiv.org/abs/1608.03983 (but one cycle only)\n",
    "    if args.lr_rampdown_epochs:\n",
    "        assert args.lr_rampdown_epochs >= args.epochs\n",
    "        lr *= ramps.cosine_rampdown(epoch, args.lr_rampdown_epochs)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "\n",
    "def update_ema_variables(model, ema_model, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(param.data, alpha=1-alpha)\n",
    "\n",
    "\n",
    "def train(train_loader, model, ema_model, optimizer, epoch):\n",
    "    global global_step\n",
    "\n",
    "    # for class criterion  --zys\n",
    "    class_criterion = nn.CrossEntropyLoss(ignore_index=NO_LABEL, reduction='sum').cuda()  # for class cost, between labeled target and student model  --zys\n",
    "\n",
    "    # for consistency cost between student model and teacher model  --zys\n",
    "    if args.consistency_type == 'mse':    # Mean Squared Error  --zys\n",
    "        consistency_criterion = softmax_mse_loss\n",
    "    elif args.consistency_type == 'kl':    # KL-divergence  --zys\n",
    "        consistency_criterion = softmax_kl_loss\n",
    "    else:\n",
    "        assert False, args.consistency_type\n",
    "        \n",
    "    # residual logit criterion??? --zys\n",
    "    residual_logit_criterion = symmetric_mse_loss\n",
    "\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    meters = AverageMeterSet()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    ema_model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, ((input, ema_input), target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        meters.update('data_time', time.time() - end)\n",
    "\n",
    "        adjust_learning_rate(optimizer, epoch, i, len(train_loader))\n",
    "\n",
    "        meters.update('lr', optimizer.param_groups[0]['lr'])\n",
    "\n",
    "#         input_var = torch.autograd.Variable(input)\n",
    "        input_var = input.to('cuda')\n",
    "        # ema_input_var = torch.autograd.Variable(ema_input, volatile=True)\n",
    "#         ema_input_var = torch.autograd.Variable(ema_input)        # --zys\n",
    "        ema_input_var = ema_input.to('cuda')\n",
    "        # target_var = torch.autograd.Variable(target.cuda(async=True))\n",
    "#         target_var = torch.autograd.Variable(target.cuda())   # --zys\n",
    "        target_var = target.to('cuda')\n",
    "\n",
    "        minibatch_size = len(target_var)\n",
    "        '''target_var.data:unlabeled target=-1; labeled target=a num(0-9),\n",
    "        target_var.ne(NO_LABEL): make labeled target=False; unlabeled target=True; And then calculate sum\n",
    "        of unlabeled target   --zys\n",
    "        '''\n",
    "        labeled_minibatch_size = target_var.data.ne(NO_LABEL).sum()   \n",
    "#         print(labeled_minibatch_size)   # --zys\n",
    "        assert labeled_minibatch_size > 0\n",
    "        meters.update('labeled_minibatch_size', labeled_minibatch_size)\n",
    "\n",
    "        ema_model_out = ema_model(ema_input_var)      # output of teacher model.  --zys\n",
    "        model_out = model(input_var)              # output of student model for labeled data  --zys\n",
    "\n",
    "        if isinstance(model_out, torch.Tensor):\n",
    "            assert args.logit_distance_cost < 0    # logit_distance_cost < 0 is default, means only have one output  --zys\n",
    "            logit1 = model_out\n",
    "            ema_logit = ema_model_out\n",
    "        else:\n",
    "            assert len(model_out) == 2\n",
    "            assert len(ema_model_out) == 2\n",
    "            logit1, logit2 = model_out\n",
    "            ema_logit, _ = ema_model_out\n",
    "\n",
    "        ema_logit = ema_logit.data.clone().detach().requires_grad_(False)     # make ema_logit  --zys\n",
    "\n",
    "        if args.logit_distance_cost >= 0:\n",
    "            class_logit, cons_logit = logit1, logit2\n",
    "            res_loss = args.logit_distance_cost * residual_logit_criterion(class_logit, cons_logit) / minibatch_size\n",
    "            meters.update('res_loss', res_loss.data[0])\n",
    "        else:\n",
    "            class_logit, cons_logit = logit1, logit1      # 'class_logit' is used to update stu model; 'cons_logit' is used to update tea model --zys\n",
    "            res_loss = 0\n",
    "\n",
    "        class_loss = class_criterion(class_logit, target_var) / minibatch_size\n",
    "        # meters.update('class_loss', class_loss.data[0])\n",
    "        meters.update('class_loss', class_loss.data)   # update: self.val = val, self.sum += val * n self.count += nself.avg = self.sum / self.count   --zys\n",
    "\n",
    "        ema_class_loss = class_criterion(ema_logit, target_var) / minibatch_size\n",
    "        # meters.update('ema_class_loss', ema_class_loss.data[0])\n",
    "        meters.update('ema_class_loss', ema_class_loss.data)   # --zys\n",
    "\n",
    "        if args.consistency:\n",
    "            consistency_weight = get_current_consistency_weight(epoch)     # weight of consistency loss in total loss.  --zys\n",
    "            meters.update('cons_weight', consistency_weight)\n",
    "            consistency_loss = consistency_weight * consistency_criterion(cons_logit, ema_logit) / minibatch_size\n",
    "            # meters.update('cons_loss', consistency_loss.data[0])\n",
    "            meters.update('cons_loss', consistency_loss.data)   # --zys\n",
    "\n",
    "        else:\n",
    "            consistency_loss = 0\n",
    "            meters.update('cons_loss', 0)\n",
    "\n",
    "        loss = class_loss + consistency_loss + res_loss   # if logit_distance_cost == -1, res_loss = 0.   --zys\n",
    "        # assert not (np.isnan(loss.data[0]) or loss.data[0] > 1e5), 'Loss explosion: {}'.format(loss.data[0])\n",
    "        # assert not (np.isnan(loss.data) or loss.data > 1e5), 'Loss explosion: {}'.format(loss.data)   #  --zys\n",
    "        # meters.update('loss', loss.data[0])\n",
    "        meters.update('loss', loss.data)  #   --zys\n",
    "\n",
    "        prec1, prec5 = accuracy(class_logit.data, target_var.data, topk=(1, 5))    # top1 and top5 accuracy of stu model.   --zys\n",
    "        \n",
    "        \n",
    "        meters.update('top1', prec1, labeled_minibatch_size)\n",
    "        meters.update('error1', 100. - prec1, labeled_minibatch_size)\n",
    "        meters.update('top5', prec5, labeled_minibatch_size)\n",
    "        meters.update('error5', 100. - prec5, labeled_minibatch_size)\n",
    "\n",
    "        ema_prec1, ema_prec5 = accuracy(ema_logit.data, target_var.data, topk=(1, 5))       # top1 and top5 accuracy of tea model.   --zys\n",
    "        meters.update('ema_top1', ema_prec1, labeled_minibatch_size)\n",
    "        meters.update('ema_error1', 100. - ema_prec1, labeled_minibatch_size)\n",
    "        meters.update('ema_top5', ema_prec5, labeled_minibatch_size)\n",
    "        meters.update('ema_error5', 100. - ema_prec5, labeled_minibatch_size)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "        update_ema_variables(model, ema_model, args.ema_decay, global_step)       # theta = alpha*theta_{t-1} + (1-theta)*theta_t, 'ema-decay' means momentum  --zys\n",
    "\n",
    "        # measure elapsed time\n",
    "        meters.update('batch_time', time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "#         if i % args.print_freq == 0:\n",
    "#             LOG.info(\n",
    "#                 'Epoch: [{0}][{1}/{2}]\\t'\n",
    "#                 'Time {meters[batch_time]:.3f}\\t'\n",
    "#                 'Data {meters[data_time]:.3f}\\t'\n",
    "#                 'Class {meters[class_loss]:.4f}\\t'\n",
    "#                 'Cons {meters[cons_loss]:.4f}\\t'\n",
    "#                 'Prec@1 {meters[top1]:.3f}\\t'\n",
    "#                 'Prec@5 {meters[top5]:.3f}'.format(\n",
    "#                     epoch, i, len(train_loader), meters=meters))\n",
    "#             log.record(epoch + i / len(train_loader), {\n",
    "#                 'step': global_step,\n",
    "#                 **meters.values(),\n",
    "#                 **meters.averages(),\n",
    "#                 **meters.sums()\n",
    "#             })\n",
    "            \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd70a42",
   "metadata": {},
   "source": [
    "### Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555be416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(state, is_best, dirpath, epoch):\n",
    "    filename = 'checkpoint.{}.ckpt'.format(epoch)\n",
    "    checkpoint_path = os.path.join(dirpath, filename)\n",
    "    best_path = os.path.join(dirpath, 'best.ckpt')\n",
    "    torch.save(state, checkpoint_path)\n",
    "    LOG.info(\"--- checkpoint saved to %s ---\" % checkpoint_path)\n",
    "    if is_best:\n",
    "        shutil.copyfile(checkpoint_path, best_path)\n",
    "        LOG.info(\"--- checkpoint copied to %s ---\" % best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be7688",
   "metadata": {},
   "source": [
    "### Train &Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1f054",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train(train_loader, model, ema_model, optimizer, epoch)\n",
    "    LOG.info(\"--- training epoch in %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    '''evaluate every args.evaluation_epochs    --zys'''\n",
    "    if args.evaluation_epochs and (epoch + 1) % args.evaluation_epochs == 0:\n",
    "        start_time = time.time()\n",
    "        LOG.info(\"Evaluating the primary model:\")\n",
    "        prec1 = validate(eval_loader, model, validation_log, global_step, epoch + 1)\n",
    "        LOG.info(\"Evaluating the EMA model:\")\n",
    "        ema_prec1 = validate(eval_loader, ema_model, ema_validation_log, global_step, epoch + 1)\n",
    "        LOG.info(\"--- validation in %s seconds ---\" % (time.time() - start_time))\n",
    "        is_best = ema_prec1 > best_prec1\n",
    "        best_prec1 = max(ema_prec1, best_prec1)\n",
    "    \n",
    "    else:\n",
    "        is_best = False\n",
    "    \n",
    "    '''save checkpoint every args.checkpoint_epochs    --zys'''\n",
    "    if args.checkpoint_epochs and (epoch + 1) % args.checkpoint_epochs == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'global_step': global_step,\n",
    "            'arch': args.arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'ema_state_dict': ema_model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, checkpoint_path, epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3fa776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from  mean_teacher import architectures\n",
    "\n",
    "SimCLR = torch.load('SimCLR.pth')\n",
    "SimCLR['model']\n",
    "\n",
    "model_params = dict(num_classes=10)\n",
    "model = architectures.SSL_model(**model_params).cuda()\n",
    "\n",
    "model.load_state_dict(SimCLR['model'], strict=False)\n",
    "model.parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
